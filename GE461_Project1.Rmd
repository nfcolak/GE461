---
title: "Report for Dodgers Management"
output: html_document
date: "2023-04-23"
author: "Necati Furkan Çolak - 21803512 / Müge Evran - 21802098 / Aslı Dinç - 21802527"
---

## **Imports:**

```{r}
library(ggplot2)
library(tidyverse)
library(magrittr)
library(dplyr)
library(GGally)
library(pander)
library(dplyr)
library(car)
library(RSQLite)
library(car)
```

In that project, we aim to build a linear regression model to analyze and predict the football matches played by Dodgers. The predictors are analyzed in terms of attend column of the data.

## Pre-process:

Firstly, we need to connect database that is given to us.

```{r}
conn <- dbConnect(SQLite(), dbname = "dodgers.sqlite")
df <- dbGetQuery(conn, "SELECT * FROM events")
dbDisconnect(conn)
```

Then, we should look at if there is any null or blank cells in all data.

```{r}
if (any(is.na(df))) {
  print("There are null values in the dataset.")
} else {
  print("There are no null values in the dataset.")
}
```

There is no null value in our data. Then we can move with the next step, we need to analyze the data to get meaningful insights from it. Let we look at the first six rows of the data.

```{r}
head(df) 
num_rows <- nrow(df) 
num_cols <- ncol(df)
cat("The data frame has", num_rows, "rows and", num_cols, "columns.\n")
```

```{r}
column_names <- colnames(df)
column_names
```

When we look at the shape of the data, we see that there are 12 columns and 81 rows. Let we analyze all columns.

```{r}
df
```

**Month:** In month column, we see that the data is collected from April to October. The column is qualitative.

**Day:** Day column shows that in which day the competition performed. The column is quantitative.

**Attend:** Attend is our label column, the columns shows that how many people attend the competitions. The column is quantitative.

**Day_of_week:** The column shows that in which day of the week competitions are performed. This column also one of the qualitative columns in our data.

**Opponent:** The column shows which team the Dodgers will play against. It's also qualitative data.

**Temp:** Temperature column shows temperature in competition day. It's quantitative data.

**Skies:** Skies column shows the weather conditions in competition day. It's qualitative data.

**Day_Night:** Day_night column shows in which time of the day competitions is performed. It's qualitative data too.

**Cap:** Cap column shows that whether cap is sold or not during the competition. The column is qualitative.

**Shirt:** Shirt column shows that whether shirt is sold or not during the competition. The column is qualitative.

**Fireworks:** The column shows whether there was a fireworks display during the match or not. The column is qualitative.

**Bobblehead:** Bobblehead column shows that whether bobblehead is sold or not during the competition. The column is qualitative.

The qualitative column needs to be factorized to make meaningful calculations over data.

```{r}
df <- df %>% mutate(
             month = factor(month),
             day_of_week=factor(day_of_week),
             skies = factor(skies),
             day_night = factor(day_night),
             cap = factor(cap),
             shirt = factor(shirt),
             fireworks = factor(fireworks),
             bobblehead = factor(bobblehead),
             opponent = factor(opponent))
summary(is.na(df))
```

We decide to move attend column to the end of data.

```{r}
label <- df$attend
df$attend <- NULL
df$attend <- label
df
```

Now, we have finished the pre-process of data.

## Data Visualization:

Let we visualize our data to get meaningful insights. We start with the pair plots.

```{r}

my_fn <- function(data, mapping, method="loess", ...){
      p <- ggplot(data = data, mapping = mapping) + 
      geom_point() + 
      geom_smooth(formula = y ~ x,method=method,se=F, ...)
      p
}

select(df, -opponent) %>% 
  ggpairs(progress = FALSE,
          upper = list(continuous = my_fn),
          lower = list(continuous = "cor"))
```

Since, most of our data is qualitative we do not use correlation matrix since correlation matrixs are valid for only quantitative data. Then, we continue with the bar charts.

```{r}
#BAR CHARTS FOR EVERY QUALITATIVE COLUMN
average_attendance_per_month <- df %>%
  group_by(month) %>%
  summarize(average_attend = mean(attend, na.rm = TRUE))

average_attendance_per_month %>%
  ggplot(aes(x = month, y = average_attend, fill = month)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  ylab("Average Attendance") +
  xlab("Month")



average_attendance_per_dayofweek <- df %>%
  group_by(day_of_week) %>%
  summarize(average_attend2 = mean(attend, na.rm = TRUE))

average_attendance_per_dayofweek %>%
  ggplot(aes(x = day_of_week, y = average_attend2, fill = day_of_week)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  ylab("Average Attendance") +
  xlab("Day of Week")



average_attendance_skies <- df %>%
  group_by(skies) %>%
  summarize(average_attend3 = mean(attend, na.rm = TRUE))

average_attendance_skies %>%
  ggplot(aes(x = skies, y = average_attend3, fill =skies)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  ylab("Average Attendance") +
  xlab("Skies")



average_attendance_daynight <- df %>%
  group_by(day_night) %>%
  summarize(average_attend4 = mean(attend, na.rm = TRUE))

average_attendance_daynight %>%
  ggplot(aes(x = day_night, y = average_attend4, fill =day_night)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  ylab("Average Attendance") +
  xlab("Day-Night")


average_attendance_cap <- df %>%
  group_by(cap) %>%
  summarize(average_attend5 = mean(attend, na.rm = TRUE))

average_attendance_cap %>%
  ggplot(aes(x = cap, y = average_attend5, fill =cap)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  ylab("Average Attendance") +
  xlab("Cap")



average_attendance_shirt <- df %>%
  group_by(shirt) %>%
  summarize(average_attend6 = mean(attend, na.rm = TRUE))

average_attendance_shirt %>%
  ggplot(aes(x = shirt, y = average_attend6, fill =shirt)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  ylab("Average Attendance") +
  xlab("Shirt")




average_attendance_fireworks <- df %>%
  group_by(fireworks) %>%
  summarize(average_attend7 = mean(attend, na.rm = TRUE))

average_attendance_fireworks %>%
  ggplot(aes(x = fireworks, y = average_attend7, fill =fireworks)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  ylab("Average Attendance") +
  xlab("Fireworks")



average_attendance_bobblehead <- df %>%
  group_by(bobblehead) %>%
  summarize(average_attend8 = mean(attend, na.rm = TRUE))

average_attendance_bobblehead %>%
  ggplot(aes(x = bobblehead, y = average_attend8, fill =bobblehead)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  ylab("Average Attendance") +
  xlab("Bobblehead")

average_attendance_opponent<- df %>%
  group_by(opponent) %>%
  summarize(average_attend9 = mean(attend, na.rm = TRUE))

average_attendance_opponent %>%
  ggplot(aes(x = opponent, y = average_attend9, fill =opponent)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  ylab("Average Attendance") +
  xlab("Opponents")
```

-   **Chart-1:** This chart shows the distribution of average attendance to matches with respect to the months of the year. It can be seen that the maximum average participation is observed in June, followed by July and August.

-   **Chart-2:** This chart shows the distribution of average attendance to matches with respect to the days of the week. It can be seen that the maximum average participation is observed in Tuesday.

-   **Chart-3:** This chart shows the distribution of average attendance to matches with respect to the condition of the sky. It can be seen that the maximum average participation is observed when the sky is clear.

-   **Chart-4:** This chart shows the distribution of average attendance to matches with respect to the game is played in day light or night. It can be seen that there is not too much difference among these two parameters but the average attendance is higher when the match is played in day light.

-   **Chart-5:** This chart shows the distribution of average attendance to matches with respect to the cap promotions. It can be seen that the maximum participation on average in the matches is when no cap promotions are run.

-   **Chart-6:** This chart shows the distribution of average attendance to matches with respect to the shirt promotions. It can be seen that the maximum participation on average in the matches is when shirt promotions are run.

-   **Chart-7:** This chart shows the distribution of average attendance to matches with respect to whether fireworks are present. It can be seen that the average participations in the matches are approximately equal.

-   **Chart-8:** This chart shows the distribution of average attendance to matches with respect to the bobblehead promotions. It can be seen that the maximum participation on average in the matches is when bobblehead promotions are run.

-   **Chart-9:** This chart shows the distribution of average attendance to matches with respect to the opponents. It can be seen that the maximum participation on average in the matches is when the opponents are Angels and Mets, followed by Nationals.

You can also find box-plot for month and day_of_week predictors;

```{r}
df %>% 
  ggplot(aes(day_of_week, attend)) +
  geom_boxplot()

df %>% 
  ggplot(aes(month, attend)) +
  geom_boxplot()
```

Distribution of attendance with temperature change;

```{r}
df %>% 
  ggplot(aes(temp,attend))+
  geom_point()+
  geom_smooth(se=FALSE)
```

Maximum attendance is observed when temp is approximately 75.

## **Modelling:**

Firstly, we construct a model with every predictor in data.

```{r}
lmod1 <- lm(attend ~ ., data = df)
summary(lmod1)
```

```{r}
aic_value1 <- AIC(lmod1)
aic_value1
```

## **Comments on first linear regression model:**

-   In first look, bobblehead, cap and some of day_of_week predictors are seems only significant predictors on the model. The Adjusted R-squared value is 0.4808.

-   Although there is a quite high Multiple R-squared performance, Adjusted R-squared stays below Multiple R-squared. The reason why this situation happens is there are too much predictors on the model that penalizes Adjusted R-squared value.

Let we check diagnostic plots for the lmod1;

```{r}
plot(lmod1)
```

-   **Residual vs Fitted Plot:** Residual vs Fitted plot looks non-linear since the red line looks somehow curved so U shape is observed. Also, data distributed equally on the both side of the graph. No funnel shape observed. 3 outliers are observed which are 13, 71 and 81.

-   **Q-Q Plot:** Points follows dashed line somehow it seems that data can be close to normal distribution. However, there is a significant decay at upper tail in terms of the slope of line. Also in ideal form, all points should be expected between 1 and -1 in Q-Q Plot. 18,1 and 71 can be considered as outlier points in this plot.

-   **Scale-Location Plot:** In ideal form, scale-location point should be close to straight line. In plot 1,18 and 71 are the outliers.

-   **Residual vs Leverage Plot:** No influential points are observed. 1, 71 and 70 are outliers according to residuals vs leverage plot.

Now we add some extra predictors to the our original model, `lmod1`.

In that case, we decide to add some meaningful interactions to our model. To prove that two predictor is meaningful we use fisher test. If the p value of the fisher test is smaller than the 0.1, then it can be said that there is a meaningful relationship between two predictors. It's assumed that confidence interval is 0.9. The sample test can be seen below.

```{r}
table <- table(df$day_night, df$fireworks)
fisher.test(table, conf.level = 0.90)
# There is a meaningful relationship
```

Also, in heat-map it can be observed the impact of day_of_week column and opponent column to the attendance.

```{r}
xtabs(attend ~ day_of_week + opponent, df) %>% 
  heatmap( 
    scale="column", 
    cexCol=0.8, cexRow=0.8 # font size
  )
```

We choose to add interactions because there are not too much quantitative data so we think that interactions can be useful to increase number of predictors.

```{r}
lmod2 <- lm(attend ~ month + day + day_of_week + opponent + temp + skies + day_night + cap + shirt + fireworks + bobblehead + day:day_of_week + day_night:fireworks + temp:day_of_week + temp:day + day:bobblehead + skies:bobblehead + month:day_night, data = df)
summary(lmod2)
```

```{r}
aic_value2 <- AIC(lmod2)
aic_value2
```

## **Comments on second linear regression model:**

-   When we add interactions our model's performance is increased from 0.4808 to 0.5966.

-   Unlike first model some NA values occurred. The reason why this situation can be multicollinearity. We'll update our model to disappear NA values.

-   Multiple R-squared performance is also increased since the number of predictors increased. Due to that reason we consider our primary performance metric as Adjusted R-squared.

-   In the second model, F-statistic is increased from 3.057 to 3.112. It means that model 2 capture more variance then model 1 couldn't capture. Therefore, model 2 shows better performance.

### Removal of NA values:

-   Since, shirt:bobblehead and day_night:fireworks does not influence model too much, we decided to eliminate these predictors. However, month:day_night can be significant at some levels. So, we decided to keep this interaction variable.

```{r}
df %>% count(day_night)
df %>% count(month)
```

The number of October data is quite few, so we decide to check all rows that is in month October.

```{r}
df_filtered <- df %>% filter(month == "OCT")
df_filtered
```

It seems that month=October and day_night column has perfect multicollinearity since in month October all day_night column shows night.

Let we filter data to avoid this situation,

```{r}
df2 <- df %>% filter(month != "OCT") %>% droplevels()
df2$month %>% levels()
```

Now, we can construct our third linear regression model with our filtered data.

```{r}
lmod3 <-lm(formula = attend ~ month + day + day_of_week + opponent + 
    temp + skies + day_night + cap + shirt + fireworks + bobblehead + 
    day:day_of_week + day_night:fireworks + 
    temp:day_of_week + temp:day + day:bobblehead + skies:bobblehead + 
    -month:day_night - bobblehead:shirt - day_night:fireworks, data = df2) 
summary(lmod3)
```

```{r}
aic_value3 <- AIC(lmod3)
aic_value3
```

## **Comments on third linear regression model:**

-   Since some predictors are eliminated, we observed decreasement over Adjusted R-squared

-   Model_3 shows better performance on AIC when we compare model_2 and model_3. The reason why model_3 shows better performance is model becomes more simple in model 3 since we drop some predictors.

Let we check diagnostic plots for the lmod3;

```{r}
plot(lmod3)
```

-   **Residual vs Fitted Plot:** Residual vs Fitted plot looks wavy over dashed line but U shape, observed in model1, is disappeared. The distribution of data looks somehow equal however outliers are acummulated upper part of the dashed line. The 13,5 and 48 looks outliers in model 3. Model starts to fit dashed-line as expected.

-   **Q-Q Plot:** Points follows dashed line it seems that model holds normality assumption in certain degree. In tails decays from the slope is observed. There are points that outside of the point 1 and -1. Nearly, 1, 5 and 2 are the outliers observed in Q-Q plot.

-   **Scale-Location Plot:** The line in the scale-location plot is now flatter and more horizontal with respect to Model 1, indicating that the data is now better captured by linear regression.

-   **Residual vs Leverage Plot:** Influential points observed in residual vs leverage plot. Indicating that 1,3 and 2 are influential points for the model 3 since their cook distance is bigger than 0.5.

Then we use `step()` to identify which variables are more crucial for the model. In the result of step, we get smaller model than previous ones but AIC, F-Statistics and Adjusted R-squared will be improved. To construct this method, we use anova tables also.

```{r}
res <- lmod3
anova(update(res, . ~ 1), res)
step(res) %>% pander()
```

`Step(),`reduced our model to;

`attend ~ day + day_of_week + opponent + temp + fireworks + bobblehead + day_of_week:temp`

This suggests that these variables have a greater utility in explaining the variability of our data. With this method, our objective is to obtain a parsimonious model that effectively captures the variance in our data.

```{r}
lmod4 <- lm(attend ~ day + day_of_week + opponent + temp + fireworks + bobblehead + 
    day_of_week:temp, df2)
summary(lmod4)
```

```{r}
aic_value4 <- AIC(lmod4)
aic_value4
```

### Comparison of previous models with final models respect to F-test:

F-test is used to compare predictors' variance or model's variance. If the variances are equal then model output gives 1.

#### Model 1 vs Model 4:

```{r}
test_result1 <- var.test(lmod1, lmod4)
test_result1
```

In this test, we compare the variances of model-3 and model-4. The output of the test shows that we fail to reject null hypothesis since p value is greater than 0.05. In other words, we cannot say that there is a significant variance change between two models.

However, variances are similar since ratio of variances is 1.34167. It means that the process over model has changed variance significantly from model 1 to model 4.

#### Model 2 vs Model 4:

```{r}
test_result2 <- var.test(lmod2, lmod4)
test_result2
```

In this test, we compare the variances of model-2 and model-4. The output of the test shows that we fail to reject null hypothesis since p value is greater than 0.05. In other words, we cannot say that there is a significant variance change between two models.

However, variances are very similar since ratio of variances is 1.0424. It means that variances of model 2 and model 4 is quite close to each other. This situation is expected since model 2 is our second best model with 0.59 Adjusted R Squared score. It also shows that with less predictors model 4 can capture more variance than model 2.

#### Model 3 vs Model 4:

```{r}
test_result3 <- var.test(lmod3, lmod4)
test_result3
```

In this test, we compare the variances of model-3 and model-4. The output of the test shows that we fail to reject null hypothesis since p value is greater than 0.05. In other words, we cannot say that there is a significant variance change between two models.

However, variances are similar since ratio of variances is 1.149 and the ratio is quite close to value 1. This situation is expected since model 4 is reduced version of model 3.

## **Comments on fourth linear regression model (final model):**

-   Model's performance has significantly increased from beginning to now. In first pace, first model's performance is around 0.48 now we elevate this performance to the 0.6172 with selection of most meaningful columns.

-   In model 4, the highest F-statistics score is observed. It shows that predictors of the model shows better performance on explaining variance of linear regression model.

-   Bobblehead, opponents and day_of_week are the most crucial variables to explain attendance on matches.

-   Since number of predictors decreased in our final model, it can be said that model complexity has decreased. Because of this situation, we get better AIC results since parameter AIC decreases as model become less complex.

```{r}
plot(lmod4)
```

-   **Residual vs Fitted Plot:** The residual vs fitted plot indicates a linear pattern between the residuals and the fitted values from 0 to 50000 and it refers that the model can make accurate predictions within this range. However, the curved pattern at the end suggests that the model may not perform efficiently and leads to a U shape in the plot which may refer to nonlinearity in the data. Adding new predictors into model may be a possible solution to address that problem. For this model, 48, 71 and 14 looks outlier points in Residual vs Fitted Plot and should be investigated.

-   **Q-Q Plot:** Points follows dashed line and normality assumption is holded for the model. In tails there are decays from the dashed line. Also there are 3 outlier points which are 48,14 and 71 that should be further investigated. There are points above 1 and -1 in Q-Q plot. In optimal model, such points should not be occured.

-   **Scale-Location Plot:** Scale location point looks straight it seems that model is improved as it can. On the end tail, there is a curvature structure upwards. This situation is caused since distribution of data is not equal at the end of the data. No funnel shape observed.

-   **Residual vs Leverage Plot:** Unlike model 3, no influential points are observed in our data since all point's cook distance value is lower than 0.5.

## Suggestions for Dodgers Management:

-   Our analysis has shown that bobblehead is the most significant predictor of attendance and is positively correlated with attendance. Therefore, selling Bobbleheads could be an important strategy for increasing attendance at Dodgers matches.

-   In addition, we found that Fireworks is another significant predictor in our model, and is positively correlated with attendance. This suggests that holding Fireworks displays can lead to an increase in the number of attendees at Dodgers matches.

-   On the other hand, we observed that the opponent team, especially the Snakes, is a factor that significantly affects attendance numbers. We found that the opponent team "Snakes" is negatively correlated with attendance, indicating that matches played against the Snakes tend to result in a decrease in attendance. This suggests that the Dodgers may need to consider alternative strategies for attracting fans when playing against this particular opponent. Among opponents, only pirates is positively correlated with the attendance.

-   Weekday is another important component for attendance. Sunday can be prime time for the football matches. Matches are performed in Sunday increase attraction to the football matches. Saturday is our second best option for prime time.

## Predictions:

Finally, you can find different predictions for different confidence intervals. We use model 4 when we calculate predictions. Predictions are calculated for every row of the data.

**LWR:** Shows lower bound of the prediction

**UPR:** Shows upper bound of the prediction.

```{r}
predict(lmod4, df2 ,interval = "prediction", level = 0.99)
```

```{r}
predict(lmod4, df2 ,interval = "prediction", level = 0.95)
```

```{r}
predict(lmod4, df2 ,interval = "prediction", level = 0.75)
```
